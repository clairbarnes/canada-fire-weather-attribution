{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293430cf",
   "metadata": {},
   "source": [
    "# Example script to identify PPAs\n",
    "\n",
    "_Run on daily z500 field clipped to (xn,xx), (yn,yx) - gridded ERA5 z500 reanalysis can be downloaded from https://climexp.knmi.nl_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df46e11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PPA_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m  \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clear_output\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPPA_functions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mPPA\u001b[39;00m\n\u001b[1;32m      9\u001b[0m xn,xx,yn,yx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m150.0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50.0\u001b[39m,\u001b[38;5;241m40.0\u001b[39m,\u001b[38;5;241m75.0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PPA_functions'"
     ]
    }
   ],
   "source": [
    "import xarray as xr, numpy as np, geopandas as gpd, regionmask\n",
    "import glob, re, os\n",
    "\n",
    "from datetime import datetime\n",
    "from  IPython.display import clear_output\n",
    "\n",
    "import PPA_functions as PPA\n",
    "\n",
    "xn,xx,yn,yx = [-150.0,-50.0,40.0,75.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "debbdcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set thresholds to identify PPAs\n",
    "sigma_threshold = 1. # identify as PPA if anomaly is more than sigma_threshold standard deviations\n",
    "duration_threshold = 5 # days\n",
    "area_threshold = 100000. # units = km^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03e3efc",
   "metadata": {},
   "source": [
    "# Identify PPAs\n",
    "\n",
    "_Run on full gridded z500 field clipped to (xn,xx), (yn,yx)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15765e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify filename\n",
    "z500_fnm = \"era5_z500_daily_-150--50E_40-75N.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae1fd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grid cell_area for checking extent of PPAs\n",
    "! module load cdo; cdo gridarea $z500_fnm gridarea_era5.nc\n",
    "clear_output(wait = False)\n",
    "gridarea = PPA.wrap_lon(xr.open_dataset(\"gridarea_era5.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296f78c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load z500 data, convert to calendar without leap years\n",
    "da = PPA.wrap_lon(xr.open_dataset(z500_fnm)).z500.load()\n",
    "da = da.convert_calendar(\"noleap\", align_on = \"year\")\n",
    "\n",
    "# detrend and save results\n",
    "z500_det = PPA.detrend_z500(da).rename(lat = \"latitude\", lon = \"longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371f6079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get climatology (used to identify significant anomalies) and smooth\n",
    "clim_mean, clim_sd = PPA.sm_climatology(z500_det)\n",
    "clim_mean, clim_sd = [xr.Dataset(data_vars = {\"z\" : da.rolling(time = 5, center = True).mean()}) for da in [clim_mean, clim_sd]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7161dbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over all years, get PPA anomalies & save as indvidual yearly files before combining into single dataframe\n",
    "for year in np.unique(da.time.dt.year.values)[:12]:\n",
    "    \n",
    "    print(year)\n",
    "    y_fnm = \"tmp/ppa-mask_\"+str(year)+\".nc\"\n",
    "    if os.path.exists(y_fnm): continue\n",
    "\n",
    "    # select year of interest\n",
    "    da_y = z500_det.sel(time = str(year))\n",
    "\n",
    "    # if year is incomplete, print warning & skip\n",
    "    if not da_y.shape == clim_mean.z.shape:\n",
    "        print(\"Incomplete year: \", str(year))\n",
    "        continue\n",
    "    \n",
    "    # compute annual anomalies\n",
    "    da_anom = xr.Dataset(data_vars = {\"z\" : da_y - clim_mean.z.values})\n",
    "\n",
    "    # identify PPAs (must exceed specified SD threshold above mean)\n",
    "    anom_mask, ppa_mask = PPA.mask_Z500_anom_by_threshold(da_anom, clim_sd, sigma_threshold = sigma_threshold)\n",
    "\n",
    "    # mask by minimum duration criterion\n",
    "    ppa_mask = PPA.mask_array_by_duration(ppa_mask, duration_threshold)\n",
    "\n",
    "    # mask by minimum area criterion\n",
    "    ppa_mask = PPA.mask_by_area(ppa_mask, gridarea, area_threshold)\n",
    "\n",
    "    # mask by duration again to ensure masking by area hasn't led to events shorter than duration_threshold\n",
    "    ppa_mask = PPA.mask_array_by_duration(ppa_mask, duration_threshold)\n",
    "    \n",
    "    # convert PPA mask back to DataArray & add to list\n",
    "    ppa_mask = xr.DataArray(data = ppa_mask, dims = [\"time\", \"latitude\", \"longitude\"], name = \"z\", coords = dict(da_y.coords))\n",
    "    ppa_mask.to_netcdf(y_fnm)\n",
    "    \n",
    "\n",
    "    clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acdc3b1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compile all years into a single dataarray\n",
    "ppa_masks = xr.concat([xr.open_dataset(fnm) for fnm in sorted(glob.glob(\"tmp/ppa-mask_*.nc\"))], \"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb4b2f7",
   "metadata": {},
   "source": [
    "## Compute PPA time series in each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2439d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapefile and create regionmask\n",
    "sf = gpd.read_file(\"sf\").to_crs(epsg = 4326)\n",
    "rm = regionmask.mask_3D_geopandas(sf, ppa_masks.longitude, ppa_masks.latitude)\n",
    "\n",
    "ppa_ts = ppa_masks.z.where(rm).mean([\"latitude\", \"longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4b9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get monthly and (fire-season only) annual time series\n",
    "ppa_m = ppa_ts.resample(time = \"MS\").sum()\n",
    "ppa_y = ppa_m.sel(time = ppa_m.time.dt.month.isin([4,5,6,7,8,9,10])).resample(time = \"YS\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfe991b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wwa]",
   "language": "python",
   "name": "conda-env-wwa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
